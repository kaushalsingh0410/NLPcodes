{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f428ea-244c-4d29-bd1d-6a7ff2130912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ritu\n"
     ]
    }
   ],
   "source": [
    "print('Ritu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9255235-0272-4946-8cd6-867ed4aa0ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae36ad75-1c24-44e8-a03c-e4b14eede788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'E:\\kaushal\\data science\\nlp\\code\\campusx\\practice\\imdb.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3807abf3-9ca0-4974-b46c-4e5dec034209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45000 entries, 0 to 44999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    45000 non-null  object\n",
      " 1   label   45000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 703.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a740c8-d229-41ee-aa8c-8059b46599aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"When I put this movie in my DVD player, and sat down with a coke and some chips, I had some expectations. I was hoping that this movie would contain some of the strong-points of the first movie: Awsome animation, good flowing story, excellent voice cast, funny comedy and a kick-ass soundtrack. But, to my disappointment, not any of this is to be found in Atlantis: Milo's Return. Had I read some reviews first, I might not have been so let down. The following paragraph will be directed to those who have seen the first movie, and who enjoyed it primarily for the points mentioned.<br /><br />When the first scene appears, your in for a shock if you just picked Atlantis: Milo's Return from the display-case at your local videoshop (or whatever), and had the expectations I had. The music feels as a bad imitation of the first movie, and the voice cast has been replaced by a not so fitting one. (With the exception of a few characters, like the voice of Sweet). The actual drawings isnt that bad, but the animation in particular is a sad sight. The storyline is also pretty weak, as its more like three episodes of Schooby-Doo than the single adventurous story we got the last time. But dont misunderstand, it's not very good Schooby-Doo episodes. I didnt laugh a single time, although I might have sniggered once or twice.<br /><br />To the audience who haven't seen the first movie, or don't especially care for a similar sequel, here is a fast review of this movie as a stand-alone product: If you liked schooby-doo, you might like this movie. If you didn't, you could still enjoy this movie if you have nothing else to do. And I suspect it might be a good kids movie, but I wouldn't know. It might have been better if Milo's Return had been a three-episode series on a cartoon channel, or on breakfast TV.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55a4528b-6e31-48ca-a2b9-d0593c34dada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<br />', '<br />', '<br />', '<br />']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('<[^>]*>',df['text'][1])\n",
    "# re.sub('<[^>]*>',' 'df['text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65c26ea7-a68a-4f7a-ac1d-7727e88118a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        I grew up (b. 1965) watching and loving the Th...\n",
       "1        When I put this movie in my DVD player, and sa...\n",
       "2        Why do people who do not know what a particula...\n",
       "3        Even though I have great interest in Biblical ...\n",
       "4        Im a die hard Dads Army fan and nothing will e...\n",
       "                               ...                        \n",
       "44995    This is the kind of picture John Lassiter woul...\n",
       "44996    A MUST SEE! I saw WHIPPED at a press screening...\n",
       "44997    NBC should be ashamed. I wouldn't allow my chi...\n",
       "44998    This movie is a clumsy mishmash of various gho...\n",
       "44999    Formula movie about the illegitimate son of a ...\n",
       "Name: text, Length: 45000, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(lambda x: re.sub('<[^>]*>',' ',x))\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af6333f3-8ee4-4051-a473-54a9786e7e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        i grew up (b. 1965) watching and loving the th...\n",
       "1        when i put this movie in my dvd player, and sa...\n",
       "2        why do people who do not know what a particula...\n",
       "3        even though i have great interest in biblical ...\n",
       "4        im a die hard dads army fan and nothing will e...\n",
       "                               ...                        \n",
       "44995    this is the kind of picture john lassiter woul...\n",
       "44996    a must see! i saw whipped at a press screening...\n",
       "44997    nbc should be ashamed. i wouldn't allow my chi...\n",
       "44998    this movie is a clumsy mishmash of various gho...\n",
       "44999    formula movie about the illegitimate son of a ...\n",
       "Name: text, Length: 45000, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].str.lower()\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f2c7f76-a1f5-4591-ac08-e7881fc6b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'my nokri profile https://www.naukri.com/mnjuser/homepage'\n",
    "text2 = 'my linked profile http://www.linkedin.com/feed/'\n",
    "text3 = 'whatsapp www.web.whatsapp.com/'\n",
    "text4 = 'spotify https://open.spotify.com/search/waja%20tum%20ho my music playlist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f6ca27c7-b874-4476-83d4-cc210d48f143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' https://www.naukri.com/mnjuser/homepage']\n",
      "[' http://www.linkedin.com/feed/']\n",
      "[' www.web.whatsapp.com/']\n",
      "[' https://open.spotify.com/search/waja%20tum%20ho']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(' ?https?://\\S*| www\\S*',text1))\n",
    "print(re.findall(' ?https?://\\S*| www\\S*',text2))\n",
    "print(re.findall(' ?https?://\\S*| ?www\\S*',text3))\n",
    "print(re.findall(' ?https?://\\S*| www\\S*',text4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13086e1c-fb9a-47e0-b769-8f8561196933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi Ritu'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "pun = string.punctuation\n",
    "print(pun)\n",
    "str = 'Hi, Ritu!'\n",
    "re.sub(f'[{pun}]','',str )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bb2eb0aa-6345-4795-bb4f-251399b269fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = '''AFAIK=As Far As I Know\n",
    "AFK=Away From Keyboard\n",
    "ASAP=As Soon As Possible\n",
    "ATK=At The Keyboard\n",
    "ATM=At The Moment\n",
    "A3=Anytime, Anywhere, Anyplace\n",
    "BAK=Back At Keyboard\n",
    "BBL=Be Back Later\n",
    "BBS=Be Back Soon\n",
    "BFN=Bye For Now\n",
    "B4N=Bye For Now\n",
    "BRB=Be Right Back\n",
    "BRT=Be Right There\n",
    "BTW=By The Way\n",
    "B4=Before\n",
    "B4N=Bye For Now\n",
    "CU=See You\n",
    "CUL8R=See You Later\n",
    "CYA=See You\n",
    "FAQ=Frequently Asked Questions\n",
    "FC=Fingers Crossed\n",
    "FWIW=For What It's Worth\n",
    "FYI=For Your Information\n",
    "GAL=Get A Life\n",
    "GG=Good Game\n",
    "GN=Good Night\n",
    "GMTA=Great Minds Think Alike\n",
    "GR8=Great!\n",
    "G9=Genius\n",
    "IC=I See\n",
    "ICQ=I Seek you (also a chat program)\n",
    "ILU=I Love You\n",
    "IMHO=In My Honest/Humble Opinion\n",
    "IMO=In My Opinion\n",
    "IOW=In Other Words\n",
    "IRL=In Real Life\n",
    "KISS=Keep It Simple, Stupid\n",
    "LDR=Long Distance Relationship\n",
    "LMAO=Laugh My A.. Off\n",
    "LOL=Laughing Out Loud\n",
    "LTNS=Long Time No See\n",
    "L8R=Later\n",
    "MTE=My Thoughts Exactly\n",
    "M8=Mate\n",
    "NRN=No Reply Necessary\n",
    "OIC=Oh I See\n",
    "PITA=Pain In The A..\n",
    "PRT=Party\n",
    "PRW=Parents Are Watching\n",
    "QPSA?\tQue Pasa?\n",
    "ROFL=Rolling On The Floor Laughing\n",
    "ROFLOL=Rolling On The Floor Laughing Out Loud\n",
    "ROTFLMAO=Rolling On The Floor Laughing My A.. Off\n",
    "SK8=Skate\n",
    "STATS=Your sex and age\n",
    "ASL=Age, Sex, Location\n",
    "THX=Thank You\n",
    "TTFN=Ta-Ta For Now!\n",
    "TTYL=Talk To You Later\n",
    "U=You\n",
    "U2=You Too\n",
    "U4E=Yours For Ever\n",
    "WB=Welcome Back\n",
    "WTF=What The F...\n",
    "WTG=Way To Go!\n",
    "WUF=Where Are You From?\n",
    "W8=Wait...\n",
    "7K=Sick:-D Laugher\n",
    "TFW – That feeling when. TFW internet slang often goes in a caption to an image.\n",
    "MFW – My face when\n",
    "MRW – My reaction when\n",
    "IFYP – I feel your pain\n",
    "LOL – Laughing out loud\n",
    "TNTL – Trying not to laugh\n",
    "JK – Just kidding\n",
    "IDC – I don’t care\n",
    "ILY – I love you\n",
    "IMU – I miss you\n",
    "ADIH – Another day in hell\n",
    "IDC – I don’t care\n",
    "ZZZ – Sleeping, bored, tired\n",
    "WYWH – Wish you were here\n",
    "TIME – Tears in my eyes\n",
    "BAE – Before anyone else\n",
    "FIMH – Forever in my heart\n",
    "BSAAW – Big smile and a wink\n",
    "BWL – Bursting with laughter\n",
    "LMAO – Laughing my a** off\n",
    "BFF: Best friends forever\n",
    "CSL – Can’t stop laughing'''.replace(' – ','=').replace(': ','=').replace('\\t','=').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9d239406-6619-4aeb-9ddc-8a2e1443840a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AFAIK': 'As Far As I Know',\n",
       " 'AFK': 'Away From Keyboard',\n",
       " 'ASAP': 'As Soon As Possible',\n",
       " 'ATK': 'At The Keyboard',\n",
       " 'ATM': 'At The Moment',\n",
       " 'A3': 'Anytime, Anywhere, Anyplace',\n",
       " 'BAK': 'Back At Keyboard',\n",
       " 'BBL': 'Be Back Later',\n",
       " 'BBS': 'Be Back Soon',\n",
       " 'BFN': 'Bye For Now',\n",
       " 'B4N': 'Bye For Now',\n",
       " 'BRB': 'Be Right Back',\n",
       " 'BRT': 'Be Right There',\n",
       " 'BTW': 'By The Way',\n",
       " 'B4': 'Before',\n",
       " 'CU': 'See You',\n",
       " 'CUL8R': 'See You Later',\n",
       " 'CYA': 'See You',\n",
       " 'FAQ': 'Frequently Asked Questions',\n",
       " 'FC': 'Fingers Crossed',\n",
       " 'FWIW': \"For What It's Worth\",\n",
       " 'FYI': 'For Your Information',\n",
       " 'GAL': 'Get A Life',\n",
       " 'GG': 'Good Game',\n",
       " 'GN': 'Good Night',\n",
       " 'GMTA': 'Great Minds Think Alike',\n",
       " 'GR8': 'Great!',\n",
       " 'G9': 'Genius',\n",
       " 'IC': 'I See',\n",
       " 'ICQ': 'I Seek you (also a chat program)',\n",
       " 'ILU': 'I Love You',\n",
       " 'IMHO': 'In My Honest/Humble Opinion',\n",
       " 'IMO': 'In My Opinion',\n",
       " 'IOW': 'In Other Words',\n",
       " 'IRL': 'In Real Life',\n",
       " 'KISS': 'Keep It Simple, Stupid',\n",
       " 'LDR': 'Long Distance Relationship',\n",
       " 'LMAO': 'Laughing my a** off',\n",
       " 'LOL': 'Laughing out loud',\n",
       " 'LTNS': 'Long Time No See',\n",
       " 'L8R': 'Later',\n",
       " 'MTE': 'My Thoughts Exactly',\n",
       " 'M8': 'Mate',\n",
       " 'NRN': 'No Reply Necessary',\n",
       " 'OIC': 'Oh I See',\n",
       " 'PITA': 'Pain In The A..',\n",
       " 'PRT': 'Party',\n",
       " 'PRW': 'Parents Are Watching',\n",
       " 'QPSA?': 'Que Pasa?',\n",
       " 'ROFL': 'Rolling On The Floor Laughing',\n",
       " 'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
       " 'ROTFLMAO': 'Rolling On The Floor Laughing My A.. Off',\n",
       " 'SK8': 'Skate',\n",
       " 'STATS': 'Your sex and age',\n",
       " 'ASL': 'Age, Sex, Location',\n",
       " 'THX': 'Thank You',\n",
       " 'TTFN': 'Ta-Ta For Now!',\n",
       " 'TTYL': 'Talk To You Later',\n",
       " 'U': 'You',\n",
       " 'U2': 'You Too',\n",
       " 'U4E': 'Yours For Ever',\n",
       " 'WB': 'Welcome Back',\n",
       " 'WTF': 'What The F...',\n",
       " 'WTG': 'Way To Go!',\n",
       " 'WUF': 'Where Are You From?',\n",
       " 'W8': 'Wait...',\n",
       " '7K': 'Sick:-D Laugher',\n",
       " 'TFW': 'That feeling when. TFW internet slang often goes in a caption to an image.',\n",
       " 'MFW': 'My face when',\n",
       " 'MRW': 'My reaction when',\n",
       " 'IFYP': 'I feel your pain',\n",
       " 'TNTL': 'Trying not to laugh',\n",
       " 'JK': 'Just kidding',\n",
       " 'IDC': 'I don’t care',\n",
       " 'ILY': 'I love you',\n",
       " 'IMU': 'I miss you',\n",
       " 'ADIH': 'Another day in hell',\n",
       " 'ZZZ': 'Sleeping, bored, tired',\n",
       " 'WYWH': 'Wish you were here',\n",
       " 'TIME': 'Tears in my eyes',\n",
       " 'BAE': 'Before anyone else',\n",
       " 'FIMH': 'Forever in my heart',\n",
       " 'BSAAW': 'Big smile and a wink',\n",
       " 'BWL': 'Bursting with laughter',\n",
       " 'BFF': 'Best friends forever',\n",
       " 'CSL': 'Can’t stop laughing'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {}\n",
    "for i in words:\n",
    "    k,v = i.split('=')\n",
    "    dic[k]=v\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f14faaa6-dcb3-476f-97fe-c3dec47ee758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3a52727a-32f6-446a-9a67-133c0f0e0cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'IMHO he is the best'\n",
    "text2 = 'FYI delhi is the capital of india'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2f1039d5-d5cc-41c5-9d8e-c4d2b8f44048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For Your Information delhi is the capital of india'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([dic[word] if word in dic else word for word in text2.split() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3e5bbcf1-5500-4400-aecc-bd44839123e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In My Honest/Humble Opinion'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([dic[word]  for word in text1.split() if word in dic ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "65cb2316-1d96-488e-8690-3a56014c1ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi ritu hoew are you'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'hi ritu hoew are you'\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4a18d6b9-be25-4584-91aa-1b622f03b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f6e3dc99-1d2b-4c79-9200-ea796c03ed7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi rite how are you'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = TextBlob(text)\n",
    "text1.correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a8f29815-e6dc-45fc-8221-2756a52e563a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c5c8e8bc-2e1c-49eb-a29c-00e5d2e37855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i grew up (b. 1965) watching and loving the thunderbirds. all my mates at school watched. we played \"thunderbirds\" before school, during lunch and after school. we all wanted to be virgil or scott. no one wanted to be alan. counting down from 5 became an art form. i took my children to see the movie hoping they would get a glimpse of what i loved as a child. how bitterly disappointing. the only high point was the snappy theme tune. not that it could compare with the original score of the thunderbirds. thankfully early saturday mornings one television channel still plays reruns of the series gerry anderson and his wife created. jonatha frakes should hand in his directors chair, his version was completely hopeless. a waste of film. utter rubbish. a cgi remake may be acceptable but replacing marionettes with homo sapiens subsp. sapiens was a huge error of judgment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'grew (b. 1965) watching loving thunderbirds. mates school watched. played \"thunderbirds\" school, lunch school. wanted virgil scott. one wanted alan. counting 5 became art form. took children see movie hoping would get glimpse loved child. bitterly disappointing. high point snappy theme tune. could compare original score thunderbirds. thankfully early saturday mornings one television channel still plays reruns series gerry anderson wife created. jonatha frakes hand directors chair, version completely hopeless. waste film. utter rubbish. cgi remake may acceptable replacing marionettes homo sapiens subsp. sapiens huge error judgment.'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['text'][0])\n",
    "' '.join([word for word in df['text'][0].split() if word not in stopwords.words('english')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9aacb3a4-5c95-45bc-9811-15efaedf21a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7959da34-ef8f-446a-8107-65d6befd0371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word :  ['Hi', 'Ritu.', \"I'm\", 'going', 'to', 'delhi.']\n",
      "sent :  ['Hi Ritu', \" I'm going to delhi\", '']\n"
     ]
    }
   ],
   "source": [
    "text3 = \"Hi Ritu. I'm going to delhi.\"\n",
    "print('word : ',text3.split())\n",
    "print('sent : ',text3.split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5bd835fa-4364-4f1d-8665-91df03ad29c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'ritu,', 'how', 'are', 'you?']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# problem with split\n",
    "text4 = 'Hi ritu, how are you?'\n",
    "text4.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ae42585d-0957-4716-b3f3-dbf86e6414db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'ritu', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\w+',text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6065e99a-bac2-4ef1-b19e-d7e4215ea95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i grew up (b',\n",
       " ' 1965) watching and loving the thunderbirds',\n",
       " ' all my mates at school watched',\n",
       " ' we played \"thunderbirds\" before school, during lunch and after school',\n",
       " ' we all wanted to be virgil or scott',\n",
       " ' no one wanted to be alan',\n",
       " ' counting down from 5 became an art form',\n",
       " ' i took my children to see the movie hoping they would get a glimpse of what i loved as a child',\n",
       " ' how bitterly disappointing',\n",
       " ' the only high point was the snappy theme tune',\n",
       " ' not that it could compare with the original score of the thunderbirds',\n",
       " ' thankfully early saturday mornings one television channel still plays reruns of the series gerry anderson and his wife created',\n",
       " ' jonatha frakes should hand in his directors chair, his version was completely hopeless',\n",
       " ' a waste of film',\n",
       " ' utter rubbish',\n",
       " ' a cgi remake may be acceptable but replacing marionettes with homo sapiens subsp',\n",
       " ' sapiens was a huge error of judgment']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[^.]+',df.text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2d297d15-00c9-4ab8-b608-38c10736036a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Ritu. I'm going to delhi.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hi', 'Ritu', '.', 'I', \"'m\", 'going', 'to', 'delhi', '.']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text3)\n",
    "word_tokenize(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8fe611f8-b792-4ee3-b566-6c32845f016f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi Ritu.', \"I'm going to delhi.\"]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "718f42b9-87dc-4b36-804f-06cf70408efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'ritu', ',', 'how', 'are', 'you', '?']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "beab1b4a-a454-409f-88f8-fdbdfc527e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi ritu, how are you?']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6a82ccd2-e209-4d18-92d8-58d8ef7a078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "86360c70-e3bb-4de3-9d08-6341e859b48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text3 ['hi', 'ritu', 'going', 'to', 'delhi']\n",
      "text4 ['hi', 'ritu', 'how', 'are', 'you']\n"
     ]
    }
   ],
   "source": [
    "print('text3',simple_preprocess(text3))\n",
    "print('text4',simple_preprocess(text4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "20cfce67-0cb2-41db-ac5a-cd7f72772ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fefd13ec-dfa2-4dbc-af52-b49be4d0f92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Ritu. I'm going to delhi.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"hi ritu . i 'm go to delhi .\""
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "print(text3)\n",
    "' '.join([porter.stem(word) for word in word_tokenize(text3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a4fc8d72-e393-435e-997e-2ce776b7d708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hi ritu. i'm go to delhi.\""
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([porter.stem(word) for word in text3.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "38dd79dc-4400-47b3-b764-4c64508ae9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi ritu go to delhi'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([porter.stem(word) for word in simple_preprocess(text3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3e49f369-231d-426d-9a71-85f0ac65cb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi ritu go delhi'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([porter.stem(word) for word in simple_preprocess(text3) if word not in stopwords.words('english')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4c052337-8017-463b-a8f4-d56464de36f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'not' in stopwords.words('english') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a57b2079-2b28-4a82-9e7f-4e6635b437d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi ritu going delhi'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "' '.join([lemma.lemmatize(word) for word in simple_preprocess(text3) if word not in stopwords.words('english')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "df7a281c-05b9-4402-9c32-f67f9ee0b363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize('going')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4e97dd79-3396-4d0e-abdf-fe1cfdb35e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem('going')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64be84fa-1a64-4239-b7f9-fa21183ae0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
